{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b095802c-df2f-4e5f-8dc6-31c1bb771a2d",
   "metadata": {},
   "source": [
    "# Modelo 3: LSTM(Bilstm) + CRF + embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a035bd-c690-4d9f-8ade-a0ec47203231",
   "metadata": {},
   "source": [
    "Realizado por:\n",
    "- Jose Luis Hincapie Bucheli (2125340)\n",
    "- Sebastián Idrobo Avirama (2122637)\n",
    "- Paul Rodrigo Rojas Guerrero (2127891)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5761cc7-32b8-436c-860e-a64277550e2a",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce5783-8927-40fb-96dc-41dd984c901e",
   "metadata": {},
   "source": [
    "# Instalación de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0d86e-f085-4dcd-8b1a-5df3b9f7ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import seqeval\n",
    "except ModuleNotFoundError as err:\n",
    "    !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66d0ac-8648-48ad-9e20-2ef24437fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons==.0.23.0\n",
    "!pip install tensorflow==2.15.0\n",
    "!pip install keras==2.15.0\n",
    "!pip install nltk==3.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f3668-0831-47ab-a93f-61f2fe940be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489dcebf-00a8-4a87-953c-100f8db5fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory to the system path\n",
    "sys.path.append('./packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f53f7-79fb-4e9a-bb60-fe71a852f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "#from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report as eskclarep\n",
    "#from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "#from seqeval.metrics import classification_report as seqclarep\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "from crfta import CRF as crf4\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import datetime, os\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593432c-ffa7-4ca3-aa6a-ba804166c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('conll2002')\n",
    "nltk.corpus.conll2002.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283fecd-1aab-45b8-b7fc-651df2ab0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
    "eval_sents = list(nltk.corpus.conll2002.iob_sents('esp.testa'))\n",
    "print(len(train_sents),len(max(train_sents,key=len)))\n",
    "print(len(test_sents),len(max(test_sents,key=len)))\n",
    "print(len(eval_sents),len(max(eval_sents,key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011a8e4-ac09-4758-856e-f5c695dd90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e17f3-5d2c-4c13-b4a2-50ea681cf9ee",
   "metadata": {},
   "source": [
    "# Parte 1: Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0656f-6133-4360-987e-d898a83a3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf6591-5379-447f-865b-386a00b7763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2tokens(train_sents[0])[0]\n",
    "#sent2labels(train_sents[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1b24f-bd70-46b9-b4d1-dc20f113cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = [sent2tokens(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2tokens(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_eval = [sent2tokens(s) for s in eval_sents]\n",
    "y_eval = [sent2labels(s) for s in eval_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecfceae-3ea8-45b7-ba19-15e03ed51411",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[2])\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860205da-836e-4f04-8763-170df4de032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words, tagsss = set([]), set([])\n",
    "\n",
    "for s in (X_train + X_eval + X_test):\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "\n",
    "for ts in (y_train + y_eval + y_test):\n",
    "    for t in ts:\n",
    "        tagsss.add(t)\n",
    "\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    "\n",
    "tag2index = {t: i + 2 for i, t in enumerate(list(tagsss))}\n",
    "tag2index['-PAD-'] = 0  # The special value used to padding\n",
    "tag2index['-OOV-'] = 1  # The special value used to padding\n",
    "\n",
    "print (len(word2index))\n",
    "print (len(tag2index))\n",
    "print(tag2index)\n",
    "\n",
    "\n",
    "print(tagsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691246a-ea07-4e07-a5a5-72f88a397c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_X, eval_sentences_X, test_sentences_X, train_tags_y, eval_tags_y, test_tags_y = [], [], [], [], [], []\n",
    "\n",
    "for s in X_train:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "\n",
    "    train_sentences_X.append(s_int)\n",
    "\n",
    "for s in X_eval:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "\n",
    "    eval_sentences_X.append(s_int)\n",
    "\n",
    "for s in X_test:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "\n",
    "    test_sentences_X.append(s_int)\n",
    "\n",
    "for s in y_train:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "\n",
    "    train_tags_y.append(s_int)\n",
    "\n",
    "for s in y_eval:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "\n",
    "    eval_tags_y.append(s_int)\n",
    "\n",
    "for s in y_test:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "\n",
    "    test_tags_y.append(s_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab839cb-b45a-4c41-860d-868d4f57180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Longitudes de las Matrices:\")\n",
    "print(len(train_sentences_X))\n",
    "print(len(eval_sentences_X))\n",
    "print(len( test_sentences_X))\n",
    "print(len(train_tags_y))\n",
    "print(len(eval_tags_y))\n",
    "print(len(test_tags_y))\n",
    "\n",
    "print(\"\\nMuestra de Datos presentes en las Matrices con las transformaciones:\\n\")\n",
    "\n",
    "\n",
    "print(train_sentences_X[0])\n",
    "print(eval_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(eval_tags_y[0])\n",
    "print(test_tags_y[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446a9f3-11e1-429f-82c8-7836b807ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_LENGTH=202\n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "eval_sentences_X = pad_sequences(eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "eval_tags_y = pad_sequences(eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "print(train_sentences_X[0])\n",
    "print(train_sentences_X.shape)\n",
    "print(eval_sentences_X[0])\n",
    "print(eval_sentences_X.shape)\n",
    "print(test_sentences_X[0])\n",
    "print(test_sentences_X.shape)\n",
    "print(train_tags_y[0])\n",
    "print(train_tags_y.shape)\n",
    "print(eval_tags_y[0])\n",
    "print(eval_tags_y.shape)\n",
    "print(test_tags_y[0])\n",
    "print(test_tags_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977ae89-4d2d-4dd1-aa8f-c3c52aeff181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categoricals(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfee0ba-bf72-452b-ae8d-e5fa83b12d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data):\n",
    "    print('Shape of data (BEFORE encode): %s' % str(data.shape))\n",
    "    encoded = to_categorical(data)\n",
    "    print('Shape of data (AFTER  encode): %s\\n' % str(encoded.shape))\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47fc76-5784-4fc3-98bd-97f5db490c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_tags_y = to_categoricals(train_tags_y, len(tag2index))\n",
    "cat_eval_tags_y  = to_categoricals(eval_tags_y, len(tag2index))\n",
    "cat_test_tags_y  = to_categoricals(test_tags_y, len(tag2index))\n",
    "\n",
    "print(cat_train_tags_y[1])\n",
    "print(len(cat_train_tags_y))\n",
    "print(cat_train_tags_y.shape)\n",
    "print(len(cat_test_tags_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fe828-7779-4b97-b7b7-d59e2f0fef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf2crf import CRF as crf6\n",
    "from wrapper import ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten, Masking\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "input = Input(shape=(MAX_LENGTH,))\n",
    "word_embedding_size = 300\n",
    "EMBED_DIM=300\n",
    "# Embedding Layer\n",
    "model = Embedding(input_dim=len(word2index),\n",
    "                output_dim=word_embedding_size,\n",
    "                input_length=MAX_LENGTH,\n",
    "                mask_zero=False)(input)\n",
    "\n",
    "# BI-LSTM Layer\n",
    "model = Bidirectional(LSTM(units=50,\n",
    "                     return_sequences=True,\n",
    "                     dropout=0.5,\n",
    "                     recurrent_dropout=0.5))(model)\n",
    "model  = Dropout(0.5, name='dropout_lstm')(model)\n",
    "model  = Dense(units=EMBED_DIM * 2, activation='relu')(model)\n",
    "model  = Dense(units=len(tag2index), activation='relu')(model)\n",
    "\n",
    "model  = Masking(mask_value=0.,input_shape=(MAX_LENGTH, len(tag2index)))(model)\n",
    "\n",
    "\n",
    "crf = crf6(units=len(tag2index), name=\"ner_crf\")\n",
    "predictions = crf(model)\n",
    "\n",
    "base_model = Model(inputs=input, outputs=predictions)\n",
    "model = ModelWithCRFLoss(base_model, sparse_target=True)\n",
    "\n",
    "model.compile(optimizer='adam')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883e776-e7a2-4e28-8055-92f719505a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(train_sentences_X, cat_train_tags_y,\n",
    "                       validation_data=(eval_sentences_X, cat_eval_tags_y),\n",
    "                       batch_size=128,\n",
    "                       epochs=50,\n",
    "                       verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
