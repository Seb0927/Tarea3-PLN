{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b095802c-df2f-4e5f-8dc6-31c1bb771a2d",
      "metadata": {
        "id": "b095802c-df2f-4e5f-8dc6-31c1bb771a2d"
      },
      "source": [
        "# Modelo 3: LSTM(Bilstm) + CRF + embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71a035bd-c690-4d9f-8ade-a0ec47203231",
      "metadata": {
        "id": "71a035bd-c690-4d9f-8ade-a0ec47203231"
      },
      "source": [
        "Realizado por:\n",
        "- Jose Luis Hincapie Bucheli (2125340)\n",
        "- Sebastián Idrobo Avirama (2122637)\n",
        "- Paul Rodrigo Rojas Guerrero (2127891)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5761cc7-32b8-436c-860e-a64277550e2a",
      "metadata": {
        "id": "c5761cc7-32b8-436c-860e-a64277550e2a"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traer información desde Google Drive"
      ],
      "metadata": {
        "id": "8O2GWnojjdLN"
      },
      "id": "8O2GWnojjdLN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si te encuentras usando Google Colab, probablemente necesites descomentar los siguientes bloques de código y modificar las rutas para que funcione con el tuyo:"
      ],
      "metadata": {
        "id": "zje8wRxEhyq7"
      },
      "id": "zje8wRxEhyq7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Borrar esto\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y9bJnezwjPMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c951fc9c-a3db-445d-9993-9cb59066186c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "y9bJnezwjPMk"
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# import os\n",
        "\n",
        "# sys.path.append('/content/drive/My Drive/Ingeniería de sistemas/Semestre 7/PLN/Taller 3 Personal/packages') # Poner Rutas de los paquetes aquí\n",
        "# sys.path.append('/content/drive/My Drive/Ingeniería de sistemas/Semestre 7/PLN/Taller 3 Personal/embeddings') # Poner Rutas de los embeddings aquí\n",
        "\n",
        "# path = '/content/drive/My Drive/Ingeniería de sistemas/Semestre 7/PLN/Taller 3 Personal/packages'\n",
        "\n",
        "# Se verifica que todo se encuentre funcionando correctamente\n",
        "# files = os.listdir(path)\n",
        "# print(files)"
      ],
      "metadata": {
        "id": "hf-D9e0gjvla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800f397c-c142-4717-98d5-ca6421e7216c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['wrapper.py', 'tf2crf.py', 'utils.py', 'crfta.py', '__pycache__']\n"
          ]
        }
      ],
      "id": "hf-D9e0gjvla"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zu0ih42kjMqg"
      },
      "id": "zu0ih42kjMqg"
    },
    {
      "cell_type": "markdown",
      "id": "7cce5783-8927-40fb-96dc-41dd984c901e",
      "metadata": {
        "id": "7cce5783-8927-40fb-96dc-41dd984c901e"
      },
      "source": [
        "# Instalación e importación de paquetes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f1f0d86e-f085-4dcd-8b1a-5df3b9f7ea21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1f0d86e-f085-4dcd-8b1a-5df3b9f7ea21",
        "outputId": "ec6a6f5d-f979-4049-814c-40b4dc032427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m30.7/43.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m748.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.4.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=ccb68fa270438731dd63faafd371170a17a26908ab5955843f22c6cc276993bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import seqeval\n",
        "except ModuleNotFoundError as err:\n",
        "    !pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dd66d0ac-8648-48ad-9e20-2ef24437fab3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd66d0ac-8648-48ad-9e20-2ef24437fab3",
        "outputId": "81949d50-0dde-4925-ccf7-d6cdb03198a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons==.0.23.0\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons==.0.23.0) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons==.0.23.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n",
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Requirement already satisfied: keras==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (2024.4.16)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (4.66.2)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.4.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons==.0.23.0\n",
        "!pip install tensorflow==2.15.0\n",
        "!pip install keras==2.15.0\n",
        "!pip install nltk==3.8.1\n",
        "!pip install seqeval\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "489dcebf-00a8-4a87-953c-100f8db5fc93",
      "metadata": {
        "id": "489dcebf-00a8-4a87-953c-100f8db5fc93"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the directory to the system path\n",
        "sys.path.append('/packages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "217f3668-0831-47ab-a93f-61f2fe940be7",
      "metadata": {
        "id": "217f3668-0831-47ab-a93f-61f2fe940be7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "#matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1e4f53f7-79fb-4e9a-bb60-fe71a852f7b3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e4f53f7-79fb-4e9a-bb60-fe71a852f7b3",
        "outputId": "3ef7bb37-1e7f-4331-c564-0b3ffedb3ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from itertools import islice\n",
        "\n",
        "#from tabulate import tabulate\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report as eskclarep\n",
        "#from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "#from seqeval.metrics import classification_report as seqclarep\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from itertools import chain\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam, schedules\n",
        "from crfta import CRF as crf4\n",
        "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import datetime, os\n",
        "import random\n",
        "import seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad1f21a5-7698-4da0-8345-177febeeef5c",
      "metadata": {
        "id": "ad1f21a5-7698-4da0-8345-177febeeef5c"
      },
      "source": [
        "# Importación de dataset conll2002"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2593432c-ffa7-4ca3-aa6a-ba804166c76e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2593432c-ffa7-4ca3-aa6a-ba804166c76e",
        "outputId": "27c8e498-d298-48e3-9bc6-2f9d13c00a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2002.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('conll2002')\n",
        "nltk.corpus.conll2002.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6283fecd-1aab-45b8-b7fc-651df2ab0995",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6283fecd-1aab-45b8-b7fc-651df2ab0995",
        "outputId": "ff00ce34-edad-4e84-fa1c-f4e9c9bbf7b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8323 1238\n",
            "1517 202\n",
            "1915 141\n"
          ]
        }
      ],
      "source": [
        "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
        "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
        "eval_sents = list(nltk.corpus.conll2002.iob_sents('esp.testa'))\n",
        "print(len(train_sents),len(max(train_sents,key=len)))\n",
        "print(len(test_sents),len(max(test_sents,key=len)))\n",
        "print(len(eval_sents),len(max(eval_sents,key=len)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c011a8e4-ac09-4758-856e-f5c695dd90bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c011a8e4-ac09-4758-856e-f5c695dd90bc",
        "outputId": "b67494fa-1523-46d7-90f8-94f5e3c75553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Melbourne', 'NP', 'B-LOC'), ('(', 'Fpa', 'O'), ('Australia', 'NP', 'B-LOC'), (')', 'Fpt', 'O'), (',', 'Fc', 'O'), ('25', 'Z', 'O'), ('may', 'NC', 'O'), ('(', 'Fpa', 'O'), ('EFE', 'NC', 'B-ORG'), (')', 'Fpt', 'O'), ('.', 'Fp', 'O')]\n"
          ]
        }
      ],
      "source": [
        "print(train_sents[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af7e17f3-5d2c-4c13-b4a2-50ea681cf9ee",
      "metadata": {
        "id": "af7e17f3-5d2c-4c13-b4a2-50ea681cf9ee"
      },
      "source": [
        "# Parte 1: Preprocesamiento de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60fc893-8440-4c03-ab84-9ee1029ff4d4",
      "metadata": {
        "id": "a60fc893-8440-4c03-ab84-9ee1029ff4d4"
      },
      "source": [
        "En esta parte, los datos que serán utilizados -conll2002- deben de ser procesados de tal manera que los tokens y labels sean separados y accedidos por medio de listas de índices y convertir las sentencias de representaciones textuales a secuencias de índices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8ac0656f-6133-4360-987e-d898a83a3b8f",
      "metadata": {
        "id": "8ac0656f-6133-4360-987e-d898a83a3b8f"
      },
      "outputs": [],
      "source": [
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [token for token, postag, label in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "61f1b24f-bd70-46b9-b4d1-dc20f113cf0e",
      "metadata": {
        "id": "61f1b24f-bd70-46b9-b4d1-dc20f113cf0e"
      },
      "outputs": [],
      "source": [
        "X_train = [sent2tokens(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2tokens(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]\n",
        "\n",
        "X_eval = [sent2tokens(s) for s in eval_sents]\n",
        "y_eval = [sent2labels(s) for s in eval_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2ecfceae-3ea8-45b7-ba19-15e03ed51411",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ecfceae-3ea8-45b7-ba19-15e03ed51411",
        "outputId": "025e4e90-be18-4776-e876-5274a3553e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['El', 'Abogado', 'General', 'del', 'Estado', ',', 'Daryl', 'Williams', ',', 'subrayó', 'hoy', 'la', 'necesidad', 'de', 'tomar', 'medidas', 'para', 'proteger', 'al', 'sistema', 'judicial', 'australiano', 'frente', 'a', 'una', 'página', 'de', 'internet', 'que', 'imposibilita', 'el', 'cumplimiento', 'de', 'los', 'principios', 'básicos', 'de', 'la', 'Ley', '.']\n",
            "['O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O']\n"
          ]
        }
      ],
      "source": [
        "print(X_train[2])\n",
        "print(y_train[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "860205da-836e-4f04-8763-170df4de032f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "860205da-836e-4f04-8763-170df4de032f",
        "outputId": "6c3ed018-00db-4b1c-aeba-b41b73cd2f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28384\n",
            "11\n",
            "{'B-LOC': 2, 'B-ORG': 3, 'B-PER': 4, 'O': 5, 'B-MISC': 6, 'I-LOC': 7, 'I-MISC': 8, 'I-PER': 9, 'I-ORG': 10, '-PAD-': 0, '-OOV-': 1}\n",
            "{'B-LOC', 'B-ORG', 'B-PER', 'O', 'B-MISC', 'I-LOC', 'I-MISC', 'I-PER', 'I-ORG'}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "words, tagsss = set([]), set([])\n",
        "\n",
        "for s in (X_train + X_eval + X_test):\n",
        "    for w in s:\n",
        "        words.add(w.lower())\n",
        "\n",
        "for ts in (y_train + y_eval + y_test):\n",
        "    for t in ts:\n",
        "        tagsss.add(t)\n",
        "\n",
        "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
        "word2index['-PAD-'] = 0  # The special value used for padding\n",
        "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
        "\n",
        "tag2index = {t: i + 2 for i, t in enumerate(list(tagsss))}\n",
        "tag2index['-PAD-'] = 0  # The special value used to padding\n",
        "tag2index['-OOV-'] = 1  # The special value used to padding\n",
        "\n",
        "print (len(word2index))\n",
        "print (len(tag2index))\n",
        "print(tag2index)\n",
        "\n",
        "\n",
        "print(tagsss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0691246a-ea07-4e07-a5a5-72f88a397c32",
      "metadata": {
        "id": "0691246a-ea07-4e07-a5a5-72f88a397c32"
      },
      "outputs": [],
      "source": [
        "train_sentences_X, eval_sentences_X, test_sentences_X, train_tags_y, eval_tags_y, test_tags_y = [], [], [], [], [], []\n",
        "\n",
        "for s in X_train:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "\n",
        "    train_sentences_X.append(s_int)\n",
        "\n",
        "for s in X_eval:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "\n",
        "    eval_sentences_X.append(s_int)\n",
        "\n",
        "for s in X_test:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "\n",
        "    test_sentences_X.append(s_int)\n",
        "\n",
        "for s in y_train:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "\n",
        "    train_tags_y.append(s_int)\n",
        "\n",
        "for s in y_eval:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "\n",
        "    eval_tags_y.append(s_int)\n",
        "\n",
        "for s in y_test:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(tag2index[w])\n",
        "        except KeyError:\n",
        "            s_int.append(tag2index['-OOV-'])\n",
        "\n",
        "    test_tags_y.append(s_int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dab839cb-b45a-4c41-860d-868d4f57180a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dab839cb-b45a-4c41-860d-868d4f57180a",
        "outputId": "370eaa7d-9c6e-4392-e260-3ce69d25162d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitudes de las Matrices:\n",
            "8323\n",
            "1915\n",
            "1517\n",
            "8323\n",
            "1915\n",
            "1517\n",
            "\n",
            "Muestra de Datos presentes en las Matrices con las transformaciones:\n",
            "\n",
            "[396, 4371, 8128, 12910, 6567, 18820, 15547, 4371, 3335, 12910, 16715]\n",
            "[20188, 12857, 4371, 20678, 12910, 6567, 1298, 15547, 4371, 17074, 12910, 16715]\n",
            "[6190, 7063, 6567, 1298, 15547, 4371, 17074, 12910, 16715]\n",
            "[2, 5, 2, 5, 5, 5, 5, 5, 3, 5, 5]\n",
            "[2, 7, 5, 2, 5, 5, 5, 5, 5, 3, 5, 5]\n",
            "[2, 7, 5, 5, 5, 5, 3, 5, 5]\n"
          ]
        }
      ],
      "source": [
        "print(\"Longitudes de las Matrices:\")\n",
        "print(len(train_sentences_X))\n",
        "print(len(eval_sentences_X))\n",
        "print(len( test_sentences_X))\n",
        "print(len(train_tags_y))\n",
        "print(len(eval_tags_y))\n",
        "print(len(test_tags_y))\n",
        "\n",
        "print(\"\\nMuestra de Datos presentes en las Matrices con las transformaciones:\\n\")\n",
        "\n",
        "\n",
        "print(train_sentences_X[0])\n",
        "print(eval_sentences_X[0])\n",
        "print(test_sentences_X[0])\n",
        "print(train_tags_y[0])\n",
        "print(eval_tags_y[0])\n",
        "print(test_tags_y[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d9daf3-60a9-45ca-8df4-533caf452818",
      "metadata": {
        "id": "57d9daf3-60a9-45ca-8df4-533caf452818"
      },
      "source": [
        "Una vez con estas variables, se debe de normalizar las matrices a partir de MAX_LENGTH, requiriendo de un array estático para servir como input de la RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7446a9f3-11e1-429f-82c8-7836b807ea19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7446a9f3-11e1-429f-82c8-7836b807ea19",
        "outputId": "9ef9f0df-c302-4249-90b3-2e49111127bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  396  4371  8128 12910  6567 18820 15547  4371  3335 12910 16715     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0]\n",
            "(8323, 202)\n",
            "[20188 12857  4371 20678 12910  6567  1298 15547  4371 17074 12910 16715\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0]\n",
            "(1915, 202)\n",
            "[ 6190  7063  6567  1298 15547  4371 17074 12910 16715     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0]\n",
            "(1517, 202)\n",
            "[2 5 2 5 5 5 5 5 3 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(8323, 202)\n",
            "[2 7 5 2 5 5 5 5 5 3 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(1915, 202)\n",
            "[2 7 5 5 5 5 3 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "(1517, 202)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "MAX_LENGTH=202\n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "eval_sentences_X = pad_sequences(eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "eval_tags_y = pad_sequences(eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "print(train_sentences_X[0])\n",
        "print(train_sentences_X.shape)\n",
        "print(eval_sentences_X[0])\n",
        "print(eval_sentences_X.shape)\n",
        "print(test_sentences_X[0])\n",
        "print(test_sentences_X.shape)\n",
        "print(train_tags_y[0])\n",
        "print(train_tags_y.shape)\n",
        "print(eval_tags_y[0])\n",
        "print(eval_tags_y.shape)\n",
        "print(test_tags_y[0])\n",
        "print(test_tags_y.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5027a94d-6339-4800-a3f9-8e8bc44bcc7d",
      "metadata": {
        "id": "5027a94d-6339-4800-a3f9-8e8bc44bcc7d"
      },
      "source": [
        "Y una vez normalizadas las matrices, se procede a representar las listas de indices de etiquetas a una representación one-hot para el procesamiento con el RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c977ae89-4d2d-4dd1-aa8f-c3c52aeff181",
      "metadata": {
        "id": "c977ae89-4d2d-4dd1-aa8f-c3c52aeff181"
      },
      "outputs": [],
      "source": [
        "def to_categoricals(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6dfee0ba-bf72-452b-ae8d-e5fa83b12d5a",
      "metadata": {
        "id": "6dfee0ba-bf72-452b-ae8d-e5fa83b12d5a"
      },
      "outputs": [],
      "source": [
        "def encode(data):\n",
        "    print('Shape of data (BEFORE encode): %s' % str(data.shape))\n",
        "    encoded = to_categorical(data)\n",
        "    print('Shape of data (AFTER  encode): %s\\n' % str(encoded.shape))\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7a47fc76-5784-4fc3-98bd-97f5db490c6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a47fc76-5784-4fc3-98bd-97f5db490c6f",
        "outputId": "77c132a9-5029-4a92-edb8-f05f8fe90eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n",
            "8323\n",
            "(8323, 202, 11)\n",
            "1517\n"
          ]
        }
      ],
      "source": [
        "cat_train_tags_y = to_categoricals(train_tags_y, len(tag2index))\n",
        "cat_eval_tags_y  = to_categoricals(eval_tags_y, len(tag2index))\n",
        "cat_test_tags_y  = to_categoricals(test_tags_y, len(tag2index))\n",
        "\n",
        "print(cat_train_tags_y[1])\n",
        "print(len(cat_train_tags_y))\n",
        "print(cat_train_tags_y.shape)\n",
        "print(len(cat_test_tags_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "737b82c6-d695-4b08-96d0-f807840f3d75",
      "metadata": {
        "id": "737b82c6-d695-4b08-96d0-f807840f3d75"
      },
      "source": [
        "# Parte 2: Entrenamiento del modelo de red"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e118c9ab-42fa-4642-a807-6ae248e7a1a4",
      "metadata": {
        "id": "e118c9ab-42fa-4642-a807-6ae248e7a1a4"
      },
      "source": [
        "Se define la red neuronal para el trabajo de NER usando el modelo LSTM(Bilstm) + CRF + embedding, importando los módulos necesarios para el mismo y también parametrizando la RNN a entrenar.\n",
        "- Se trae el embedding con tamaño de 300.\n",
        "- Se genera el modelo LSTM(Bilstm) + CRF\n",
        "- Se genera una capa de masking para que ignore los valores de 0\n",
        "\n",
        "Una vez hecho esto, se procede a entrenar la red neuronal y a testear los resultados de la misma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from gensim.models import KeyedVectors\n",
        "import numpy as np\n",
        "\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/Ingeniería de sistemas/Semestre 7/PLN/Taller 3 Personal/embeddings/word2vec_jose_sebastian_paul300.txt\",\n",
        "                                                   binary=False)\n",
        "\n",
        "word_vectors = word2vec_model\n",
        "vocab = word2vec_model.index_to_key\n",
        "\n",
        "# Aquí se inicializa el embedding\n",
        "embedding_matrix = np.zeros((len(vocab), word_vectors.vector_size))\n",
        "\n",
        "# Se llena el embedding con los datos obtenidos de Word2Vec para ser usado\n",
        "for i, word in enumerate(vocab):\n",
        "    embedding_matrix[i] = word_vectors[word]\n"
      ],
      "metadata": {
        "id": "NmmeYyvMpzI-"
      },
      "id": "NmmeYyvMpzI-",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "af1fe828-7779-4b97-b7b7-d59e2f0fef3a",
      "metadata": {
        "id": "af1fe828-7779-4b97-b7b7-d59e2f0fef3a"
      },
      "outputs": [],
      "source": [
        "# TO-DO: No se ha hecho nada diferente por el momento\n",
        "\n",
        "from tf2crf import CRF as crf6\n",
        "from wrapper import ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
        "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
        "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten, Masking\n",
        "from tensorflow.keras.optimizers import Adam, schedules\n",
        "input = Input(shape=(MAX_LENGTH,))\n",
        "word_embedding_size = 300\n",
        "EMBED_DIM=300\n",
        "# Embedding Layer\n",
        "model = Embedding(input_dim=len(vocab),\n",
        "                             output_dim=word_embedding_size,\n",
        "                             weights=[embedding_matrix],\n",
        "                             mask_zero=False)(input)\n",
        "\n",
        "# BI-LSTM Layer\n",
        "model = Bidirectional(LSTM(units=50,\n",
        "                     return_sequences=True,\n",
        "                     dropout=0.5,\n",
        "                     recurrent_dropout=0.5))(model)\n",
        "model  = Dropout(0.5, name='dropout_lstm')(model)\n",
        "model  = Dense(units=EMBED_DIM * 2, activation='relu')(model)\n",
        "model  = Dense(units=len(tag2index), activation='relu')(model)\n",
        "\n",
        "model  = Masking(mask_value=0.,input_shape=(MAX_LENGTH, len(tag2index)))(model)\n",
        "\n",
        "\n",
        "crf = crf6(units=len(tag2index), name=\"ner_crf\")\n",
        "predictions = crf(model)\n",
        "\n",
        "base_model = Model(inputs=input, outputs=predictions)\n",
        "model = ModelWithCRFLoss(base_model, sparse_target=True)\n",
        "\n",
        "model.compile(optimizer='adam')\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "2883e776-e7a2-4e28-8055-92f719505a91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2883e776-e7a2-4e28-8055-92f719505a91",
        "outputId": "fc5a847d-3b76-463b-cd72-d081323bfb53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "66/66 - 70s - loss: 68.7013 - accuracy: 0.9103 - val_loss_val: 20.1166 - val_val_accuracy: 0.9804 - 70s/epoch - 1s/step\n",
            "Epoch 2/50\n",
            "66/66 - 59s - loss: 18.5656 - accuracy: 0.9806 - val_loss_val: 16.9033 - val_val_accuracy: 0.9805 - 59s/epoch - 890ms/step\n",
            "Epoch 3/50\n",
            "66/66 - 59s - loss: 15.6048 - accuracy: 0.9807 - val_loss_val: 14.9866 - val_val_accuracy: 0.9807 - 59s/epoch - 891ms/step\n",
            "Epoch 4/50\n",
            "66/66 - 59s - loss: 13.5064 - accuracy: 0.9812 - val_loss_val: 13.6933 - val_val_accuracy: 0.9813 - 59s/epoch - 888ms/step\n",
            "Epoch 5/50\n",
            "66/66 - 59s - loss: 12.0751 - accuracy: 0.9822 - val_loss_val: 12.8275 - val_val_accuracy: 0.9819 - 59s/epoch - 891ms/step\n",
            "Epoch 6/50\n",
            "66/66 - 59s - loss: 10.8910 - accuracy: 0.9834 - val_loss_val: 12.0382 - val_val_accuracy: 0.9828 - 59s/epoch - 893ms/step\n",
            "Epoch 7/50\n",
            "66/66 - 59s - loss: 9.7544 - accuracy: 0.9850 - val_loss_val: 11.4529 - val_val_accuracy: 0.9837 - 59s/epoch - 895ms/step\n",
            "Epoch 8/50\n",
            "66/66 - 59s - loss: 8.8540 - accuracy: 0.9863 - val_loss_val: 10.8507 - val_val_accuracy: 0.9846 - 59s/epoch - 892ms/step\n",
            "Epoch 9/50\n",
            "66/66 - 59s - loss: 8.0322 - accuracy: 0.9874 - val_loss_val: 10.3804 - val_val_accuracy: 0.9853 - 59s/epoch - 891ms/step\n",
            "Epoch 10/50\n",
            "66/66 - 59s - loss: 7.1875 - accuracy: 0.9883 - val_loss_val: 9.8444 - val_val_accuracy: 0.9857 - 59s/epoch - 894ms/step\n",
            "Epoch 11/50\n",
            "66/66 - 59s - loss: 6.6421 - accuracy: 0.9891 - val_loss_val: 9.7460 - val_val_accuracy: 0.9863 - 59s/epoch - 894ms/step\n",
            "Epoch 12/50\n",
            "66/66 - 59s - loss: 6.1032 - accuracy: 0.9899 - val_loss_val: 9.3556 - val_val_accuracy: 0.9867 - 59s/epoch - 891ms/step\n",
            "Epoch 13/50\n",
            "66/66 - 59s - loss: 5.5554 - accuracy: 0.9906 - val_loss_val: 9.0947 - val_val_accuracy: 0.9870 - 59s/epoch - 893ms/step\n",
            "Epoch 14/50\n",
            "66/66 - 59s - loss: 5.2089 - accuracy: 0.9911 - val_loss_val: 9.1592 - val_val_accuracy: 0.9873 - 59s/epoch - 896ms/step\n",
            "Epoch 15/50\n",
            "66/66 - 59s - loss: 4.9194 - accuracy: 0.9918 - val_loss_val: 8.8663 - val_val_accuracy: 0.9877 - 59s/epoch - 894ms/step\n",
            "Epoch 16/50\n",
            "66/66 - 59s - loss: 4.4842 - accuracy: 0.9923 - val_loss_val: 8.7797 - val_val_accuracy: 0.9876 - 59s/epoch - 891ms/step\n",
            "Epoch 17/50\n",
            "66/66 - 59s - loss: 4.2257 - accuracy: 0.9927 - val_loss_val: 8.6232 - val_val_accuracy: 0.9879 - 59s/epoch - 897ms/step\n",
            "Epoch 18/50\n",
            "66/66 - 59s - loss: 3.9910 - accuracy: 0.9931 - val_loss_val: 8.5168 - val_val_accuracy: 0.9880 - 59s/epoch - 895ms/step\n",
            "Epoch 19/50\n",
            "66/66 - 59s - loss: 3.8845 - accuracy: 0.9935 - val_loss_val: 8.5375 - val_val_accuracy: 0.9880 - 59s/epoch - 897ms/step\n",
            "Epoch 20/50\n",
            "66/66 - 59s - loss: 3.5406 - accuracy: 0.9938 - val_loss_val: 8.3111 - val_val_accuracy: 0.9885 - 59s/epoch - 897ms/step\n",
            "Epoch 21/50\n",
            "66/66 - 59s - loss: 3.3121 - accuracy: 0.9941 - val_loss_val: 8.4348 - val_val_accuracy: 0.9887 - 59s/epoch - 895ms/step\n",
            "Epoch 22/50\n",
            "66/66 - 59s - loss: 3.1641 - accuracy: 0.9945 - val_loss_val: 8.2369 - val_val_accuracy: 0.9884 - 59s/epoch - 898ms/step\n",
            "Epoch 23/50\n",
            "66/66 - 59s - loss: 2.9747 - accuracy: 0.9948 - val_loss_val: 8.2422 - val_val_accuracy: 0.9885 - 59s/epoch - 894ms/step\n",
            "Epoch 24/50\n",
            "66/66 - 59s - loss: 2.8049 - accuracy: 0.9950 - val_loss_val: 8.2949 - val_val_accuracy: 0.9888 - 59s/epoch - 896ms/step\n",
            "Epoch 25/50\n",
            "66/66 - 59s - loss: 2.6665 - accuracy: 0.9951 - val_loss_val: 8.2185 - val_val_accuracy: 0.9891 - 59s/epoch - 894ms/step\n",
            "Epoch 26/50\n",
            "66/66 - 59s - loss: 2.5284 - accuracy: 0.9953 - val_loss_val: 8.1969 - val_val_accuracy: 0.9889 - 59s/epoch - 901ms/step\n",
            "Epoch 27/50\n",
            "66/66 - 59s - loss: 2.4658 - accuracy: 0.9956 - val_loss_val: 8.4214 - val_val_accuracy: 0.9890 - 59s/epoch - 897ms/step\n",
            "Epoch 28/50\n",
            "66/66 - 59s - loss: 2.3327 - accuracy: 0.9957 - val_loss_val: 8.5288 - val_val_accuracy: 0.9892 - 59s/epoch - 895ms/step\n",
            "Epoch 29/50\n",
            "66/66 - 59s - loss: 2.2377 - accuracy: 0.9959 - val_loss_val: 8.3502 - val_val_accuracy: 0.9890 - 59s/epoch - 895ms/step\n",
            "Epoch 30/50\n",
            "66/66 - 59s - loss: 2.1329 - accuracy: 0.9960 - val_loss_val: 8.3644 - val_val_accuracy: 0.9893 - 59s/epoch - 895ms/step\n",
            "Epoch 31/50\n",
            "66/66 - 59s - loss: 2.0441 - accuracy: 0.9962 - val_loss_val: 8.3878 - val_val_accuracy: 0.9893 - 59s/epoch - 894ms/step\n",
            "Epoch 32/50\n",
            "66/66 - 59s - loss: 1.9497 - accuracy: 0.9963 - val_loss_val: 8.5456 - val_val_accuracy: 0.9895 - 59s/epoch - 899ms/step\n",
            "Epoch 33/50\n",
            "66/66 - 59s - loss: 1.8503 - accuracy: 0.9966 - val_loss_val: 8.3863 - val_val_accuracy: 0.9893 - 59s/epoch - 901ms/step\n",
            "Epoch 34/50\n",
            "66/66 - 59s - loss: 1.7935 - accuracy: 0.9966 - val_loss_val: 8.4424 - val_val_accuracy: 0.9892 - 59s/epoch - 897ms/step\n",
            "Epoch 35/50\n",
            "66/66 - 59s - loss: 1.7272 - accuracy: 0.9967 - val_loss_val: 8.4259 - val_val_accuracy: 0.9895 - 59s/epoch - 897ms/step\n",
            "Epoch 36/50\n",
            "66/66 - 59s - loss: 1.6731 - accuracy: 0.9969 - val_loss_val: 8.5780 - val_val_accuracy: 0.9896 - 59s/epoch - 899ms/step\n",
            "Epoch 37/50\n",
            "66/66 - 59s - loss: 1.6257 - accuracy: 0.9969 - val_loss_val: 8.4635 - val_val_accuracy: 0.9895 - 59s/epoch - 899ms/step\n",
            "Epoch 38/50\n",
            "66/66 - 59s - loss: 1.5577 - accuracy: 0.9971 - val_loss_val: 8.8916 - val_val_accuracy: 0.9895 - 59s/epoch - 900ms/step\n",
            "Epoch 39/50\n",
            "66/66 - 59s - loss: 1.5507 - accuracy: 0.9971 - val_loss_val: 8.7360 - val_val_accuracy: 0.9896 - 59s/epoch - 900ms/step\n",
            "Epoch 40/50\n",
            "66/66 - 59s - loss: 1.4972 - accuracy: 0.9972 - val_loss_val: 8.8600 - val_val_accuracy: 0.9893 - 59s/epoch - 900ms/step\n",
            "Epoch 41/50\n",
            "66/66 - 59s - loss: 1.4543 - accuracy: 0.9974 - val_loss_val: 8.5663 - val_val_accuracy: 0.9892 - 59s/epoch - 901ms/step\n",
            "Epoch 42/50\n",
            "66/66 - 60s - loss: 1.3571 - accuracy: 0.9974 - val_loss_val: 9.0119 - val_val_accuracy: 0.9893 - 60s/epoch - 903ms/step\n",
            "Epoch 43/50\n",
            "66/66 - 60s - loss: 1.2724 - accuracy: 0.9976 - val_loss_val: 8.6963 - val_val_accuracy: 0.9895 - 60s/epoch - 904ms/step\n",
            "Epoch 44/50\n",
            "66/66 - 59s - loss: 1.2168 - accuracy: 0.9977 - val_loss_val: 9.0657 - val_val_accuracy: 0.9897 - 59s/epoch - 899ms/step\n",
            "Epoch 45/50\n",
            "66/66 - 59s - loss: 1.2341 - accuracy: 0.9976 - val_loss_val: 9.1026 - val_val_accuracy: 0.9897 - 59s/epoch - 900ms/step\n",
            "Epoch 46/50\n",
            "66/66 - 60s - loss: 1.1847 - accuracy: 0.9978 - val_loss_val: 9.2547 - val_val_accuracy: 0.9898 - 60s/epoch - 902ms/step\n",
            "Epoch 47/50\n",
            "66/66 - 59s - loss: 1.1226 - accuracy: 0.9978 - val_loss_val: 9.4362 - val_val_accuracy: 0.9897 - 59s/epoch - 898ms/step\n",
            "Epoch 48/50\n",
            "66/66 - 59s - loss: 1.1058 - accuracy: 0.9979 - val_loss_val: 9.2969 - val_val_accuracy: 0.9896 - 59s/epoch - 900ms/step\n",
            "Epoch 49/50\n",
            "66/66 - 60s - loss: 1.0986 - accuracy: 0.9979 - val_loss_val: 9.2641 - val_val_accuracy: 0.9897 - 60s/epoch - 904ms/step\n",
            "Epoch 50/50\n",
            "66/66 - 59s - loss: 1.0579 - accuracy: 0.9980 - val_loss_val: 9.2875 - val_val_accuracy: 0.9898 - 59s/epoch - 901ms/step\n"
          ]
        }
      ],
      "source": [
        "history= model.fit(train_sentences_X, cat_train_tags_y,\n",
        "                       validation_data=(eval_sentences_X, cat_eval_tags_y),\n",
        "                       batch_size=128,\n",
        "                       epochs=50,\n",
        "                       verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "470d90aa-4c7b-4884-b138-9a052d59ba5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "470d90aa-4c7b-4884-b138-9a052d59ba5a",
        "outputId": "c0fe1e6b-43ec-4896-fef7-829b9e18c30e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'B-LOC': 2, 'B-ORG': 3, 'B-PER': 4, 'O': 5, 'B-MISC': 6, 'I-LOC': 7, 'I-MISC': 8, 'I-PER': 9, 'I-ORG': 10, '-PAD-': 0, '-OOV-': 1}\n",
            "[[ 6190  7063  6567 ...     0     0     0]\n",
            " [28351     0     0 ...     0     0     0]\n",
            " [16668 26624 13873 ...     0     0     0]\n",
            " ...\n",
            " [ 6190 17225 13507 ...     0     0     0]\n",
            " [ 3603 11086 24629 ...     0     0     0]\n",
            " [ 6190 23086 19746 ...     0     0     0]]\n",
            "48/48 [==============================] - 4s 59ms/step\n",
            "(1517, 202)\n",
            "[[2 7 5 ... 0 0 0]\n",
            " [5 0 0 ... 0 0 0]\n",
            " [5 5 5 ... 0 0 0]\n",
            " ...\n",
            " [5 2 5 ... 0 0 0]\n",
            " [5 5 5 ... 0 0 0]\n",
            " [5 5 5 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(tag2index)\n",
        "print(test_sentences_X)\n",
        "y_pred= model.predict(test_sentences_X)\n",
        "print(y_pred.shape)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1cb09e4c-fe54-4fd0-9481-226625cfe92a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cb09e4c-fe54-4fd0-9481-226625cfe92a",
        "outputId": "5060e687-b933-4494-cc23-1f196c971edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2: 'B-LOC', 3: 'B-ORG', 4: 'B-PER', 5: 'O', 6: 'B-MISC', 7: 'I-LOC', 8: 'I-MISC', 9: 'I-PER', 10: 'I-ORG', 0: '-PAD-', 1: '-OOV-'}\n",
            "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n"
          ]
        }
      ],
      "source": [
        "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
        "index2tag = {i: t for t, i in tag2index.items()}\n",
        "print(index2tag)\n",
        "y1_pred = logits_to_tokens(y_pred, index2tag)\n",
        "print(y1_pred[10])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(Y_test[4])\n",
        "print(test_tags_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B93zbJbTd_I2",
        "outputId": "c11fa69c-ba15-4d4f-d74a-ef88f5464302"
      },
      "id": "B93zbJbTd_I2",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1517, 202)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
        "index2tag = {i: t for t, i in tag2index.items()}\n",
        "print(index2tag)\n",
        "y1_true = logits_to_tokens(test_tags_y, index2tag)\n",
        "print(y1_true[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5NsDa-meApA",
        "outputId": "38536681-2c64-4bdb-d3d7-962921523fed"
      },
      "id": "L5NsDa-meApA",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2: 'B-LOC', 3: 'B-ORG', 4: 'B-PER', 5: 'O', 6: 'B-MISC', 7: 'I-LOC', 8: 'I-MISC', 9: 'I-PER', 10: 'I-ORG', 0: '-PAD-', 1: '-OOV-'}\n",
            "['O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842d9d47-b7b8-478a-b7f6-efd5be17f762",
      "metadata": {
        "id": "842d9d47-b7b8-478a-b7f6-efd5be17f762"
      },
      "source": [
        "## Calidad obtenida del modelo\n",
        "\n",
        "Se evalua la calidad de los resultados del modelo usando las siguientes métricas: *precision, recall, accuracy* y *F1-score*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "bc937ab9-d0d4-4c83-a503-05f7432c4d76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc937ab9-d0d4-4c83-a503-05f7432c4d76",
        "outputId": "629bf9b6-5078-4467-b060-5d256d69fbd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: -PAD- seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 70.6%\n",
            "   recall: 64.8%\n",
            " accuracy: 99.1%\n",
            " F1-score: 67.5%\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import classification_report as seqclarep\n",
        "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print(\"precision: {:.1%}\".format(precision_score(y1_true, y1_pred)))\n",
        "print(\"   recall: {:.1%}\".format(recall_score(y1_true,    y1_pred)))\n",
        "print(\" accuracy: {:.1%}\".format(accuracy_score(y1_true,  y1_pred)))\n",
        "print(\" F1-score: {:.1%}\".format(f1_score(y1_true,        y1_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b947ac45-185b-4407-8883-966e1210f065",
      "metadata": {
        "id": "b947ac45-185b-4407-8883-966e1210f065"
      },
      "source": [
        "Se genera un reporte de la clasificación basada en las etiquetas predichas y las reales, esto brindado en un DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "bc3aa1f6-3de6-4026-bdb9-5d95f46f4886",
      "metadata": {
        "id": "bc3aa1f6-3de6-4026-bdb9-5d95f46f4886"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "li1 = sum(y1_true, [])\n",
        "li2 = sum(y1_pred, [])\n",
        "\n",
        "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
        "\n",
        "results['Expected'] = li1\n",
        "results['Predicted'] = li2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "a9fccdb6-6160-4d08-9fb4-443632379b03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9fccdb6-6160-4d08-9fb4-443632379b03",
        "outputId": "7cc9f845-64f9-4883-ae2e-37a0bba7fff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Class Name precision recall f1-score support\n",
            "0      -PAD-      1.00   1.00     1.00  254901\n",
            "1      B-LOC      0.79   0.70     0.74    1084\n",
            "2     B-MISC      0.46   0.39     0.42     339\n",
            "3      B-ORG      0.78   0.74     0.76    1400\n",
            "4      B-PER      0.81   0.72     0.76     735\n",
            "5      I-LOC      0.74   0.56     0.63     325\n",
            "6     I-MISC      0.49   0.38     0.43     557\n",
            "7      I-ORG      0.77   0.62     0.68    1104\n",
            "8      I-PER      0.90   0.83     0.87     634\n",
            "9          O      0.97   0.99     0.98   45355\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report as eskclarep\n",
        "report = eskclarep(results['Expected'], results['Predicted'])\n",
        "\n",
        "print(report_to_df(report))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abf3433b-4e95-4920-9a55-940d1f2f1a1c",
      "metadata": {
        "id": "abf3433b-4e95-4920-9a55-940d1f2f1a1c"
      },
      "source": [
        "Por último, se realizan evaluaciones del modelo a partir de algunas oraciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "566c99ce-8ea1-4818-8fa1-92b4b7c75ebe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "566c99ce-8ea1-4818-8fa1-92b4b7c75ebe",
        "outputId": "8c2002a6-93a5-4ffb-953d-5b04db79f0b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['James', 'Rodriguez', 'es', 'el', 'jugador', 'colombiano', 'más', 'importante', 'con', 'Radamel', 'Falcao.'], ['Jugadores', 'de', 'la', 'selección', 'Colombia', 'que', 'juegan', 'en', 'el', 'Reino', 'Unido']]\n",
            "[['La', 'federación', 'Nacional', 'de', 'cafeteros', 'de', 'Colombia', 'es', 'dirigida', 'por', 'Horacio', 'Sánchez'], ['y', 'se', 'ubica', 'en', 'las', 'ciudades', 'de', 'Cali', 'y', 'Medellín', 'con', 'el', 'instituto', 'colombiano', 'del', 'café']]\n"
          ]
        }
      ],
      "source": [
        "test_sample1 = [\n",
        "    \"James Rodriguez es el jugador colombiano más importante con Radamel Falcao.\".split(),\n",
        "    \" Jugadores de la selección Colombia que juegan en el Reino Unido\".split()\n",
        "]\n",
        "\n",
        "print(test_sample1)\n",
        "\n",
        "test_sample2 = [\n",
        "    \"La federación Nacional de cafeteros de Colombia es dirigida por Horacio Sánchez\".split(),\n",
        "    \" y se ubica en las ciudades de  Cali y Medellín con el instituto colombiano del café \".split()\n",
        "]\n",
        "\n",
        "print(test_sample2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "5f53bc58-c8c5-4962-bf78-06bff6ea5ff5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f53bc58-c8c5-4962-bf78-06bff6ea5ff5",
        "outputId": "79ce5826-fd7a-4391-c679-a8cf3b564c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6190 13622 28254  9558 13289  9558  3012 24994 25662 25286     1 22896\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]\n",
            " [ 4531 15160 26511 20507 16668  4644  9558 24897  4531     1  6404  2630\n",
            "   1307 26436   251 27896     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0]]\n",
            "(2, 202)\n"
          ]
        }
      ],
      "source": [
        "test_samples_X = []\n",
        "for s in test_sample2:\n",
        "    s_int = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            s_int.append(word2index[w.lower()])\n",
        "        except KeyError:\n",
        "            s_int.append(word2index['-OOV-'])\n",
        "    test_samples_X.append(s_int)\n",
        "\n",
        "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
        "print(test_samples_X)\n",
        "print(test_samples_X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "231b1961-c8a2-45c3-8604-f667f0225d22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "231b1961-c8a2-45c3-8604-f667f0225d22",
        "outputId": "148c380b-0de3-460e-bd21-2a968ad259af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "[[ 5  3 10 10 10 10 10  5  5  5  0  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5  5  5  5  5  5  5  5  5  5  5  5  3  5  5  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0]] (2, 202)\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(test_samples_X)\n",
        "print(predictions, predictions.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "e73ea8d2-3522-4029-a5b5-727e4fb09338",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e73ea8d2-3522-4029-a5b5-727e4fb09338",
        "outputId": "085fba9c-ba8e-4394-c0a9-b935f1dc0d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', '-PAD-', 'I-PER', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-', '-PAD-']]\n"
          ]
        }
      ],
      "source": [
        "#print(len(predictions))\n",
        "log_tokens = logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})\n",
        "print(log_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "74b160eb-4901-4278-a3ec-32fac5bf6d0d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74b160eb-4901-4278-a3ec-32fac5bf6d0d",
        "outputId": "70e9678a-f6af-4ae0-d5b8-d0bc50a24dd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: tabulate\n",
            "Successfully installed tabulate-0.9.0\n",
            "La    federación    Nacional    de     cafeteros    de     Colombia    es    dirigida    por    Horacio    Sánchez\n",
            "----  ------------  ----------  -----  -----------  -----  ----------  ----  ----------  -----  ---------  ---------\n",
            "O     B-ORG         I-ORG       I-ORG  I-ORG        I-ORG  I-ORG       O     O           O      -PAD-      I-PER\n",
            "\n",
            "\n",
            "y    se    ubica    en    las    ciudades    de    Cali    y    Medellín    con    el    instituto    colombiano    del    café\n",
            "---  ----  -------  ----  -----  ----------  ----  ------  ---  ----------  -----  ----  -----------  ------------  -----  ------\n",
            "O    O     O        O     O      O           O     O       O    O           O      O     B-ORG        O             O      -PAD-\n"
          ]
        }
      ],
      "source": [
        "!pip install tabulate\n",
        "from tabulate import tabulate\n",
        "\n",
        "heads1 = test_sample2[0]\n",
        "body1 = [log_tokens[0][:len(test_sample2[0])]]\n",
        "\n",
        "heads2 = test_sample2[1]\n",
        "body2 = [log_tokens[1][:len(test_sample2[1])]]\n",
        "\n",
        "print(tabulate(body1, headers=heads1))\n",
        "\n",
        "print (\"\\n\")\n",
        "\n",
        "print(tabulate(body2, headers=heads2))\n",
        "\n",
        "## postagging Freeling 4.1\n",
        "\n",
        "## El      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\n",
        "## DA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\n",
        "\n",
        "\n",
        "## pos tagger Stanford NLP\n",
        "\n",
        "## El      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\n",
        "## da0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}