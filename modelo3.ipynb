{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b095802c-df2f-4e5f-8dc6-31c1bb771a2d",
   "metadata": {},
   "source": [
    "# Modelo 3: LSTM(Bilstm) + CRF + embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a035bd-c690-4d9f-8ade-a0ec47203231",
   "metadata": {},
   "source": [
    "Realizado por:\n",
    "- Jose Luis Hincapie Bucheli (2125340)\n",
    "- Sebastián Idrobo Avirama (2122637)\n",
    "- Paul Rodrigo Rojas Guerrero (2127891)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5761cc7-32b8-436c-860e-a64277550e2a",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cce5783-8927-40fb-96dc-41dd984c901e",
   "metadata": {},
   "source": [
    "# Instalación e importación de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0d86e-f085-4dcd-8b1a-5df3b9f7ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import seqeval\n",
    "except ModuleNotFoundError as err:\n",
    "    !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd66d0ac-8648-48ad-9e20-2ef24437fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons==.0.23.0\n",
    "!pip install tensorflow==2.15.0\n",
    "!pip install keras==2.15.0\n",
    "!pip install nltk==3.8.1\n",
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489dcebf-00a8-4a87-953c-100f8db5fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory to the system path\n",
    "sys.path.append('./packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f3668-0831-47ab-a93f-61f2fe940be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f53f7-79fb-4e9a-bb60-fe71a852f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "#from tabulate import tabulate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report as eskclarep\n",
    "#from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "#from seqeval.metrics import classification_report as seqclarep\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from itertools import chain\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "from crfta import CRF as crf4\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import datetime, os\n",
    "import random\n",
    "import seqeval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f21a5-7698-4da0-8345-177febeeef5c",
   "metadata": {},
   "source": [
    "# Importación de dataset conll2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593432c-ffa7-4ca3-aa6a-ba804166c76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('conll2002')\n",
    "nltk.corpus.conll2002.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283fecd-1aab-45b8-b7fc-651df2ab0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train'))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb'))\n",
    "eval_sents = list(nltk.corpus.conll2002.iob_sents('esp.testa'))\n",
    "print(len(train_sents),len(max(train_sents,key=len)))\n",
    "print(len(test_sents),len(max(test_sents,key=len)))\n",
    "print(len(eval_sents),len(max(eval_sents,key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011a8e4-ac09-4758-856e-f5c695dd90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_sents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e17f3-5d2c-4c13-b4a2-50ea681cf9ee",
   "metadata": {},
   "source": [
    "# Parte 1: Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fc893-8440-4c03-ab84-9ee1029ff4d4",
   "metadata": {},
   "source": [
    "En esta parte, los datos que serán utilizados -conll2002- deben de ser procesados de tal manera que los tokens y labels sean separados y accedidos por medio de listas de índices y convertir las sentencias de representaciones textuales a secuencias de índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0656f-6133-4360-987e-d898a83a3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1b24f-bd70-46b9-b4d1-dc20f113cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2tokens(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2tokens(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_eval = [sent2tokens(s) for s in eval_sents]\n",
    "y_eval = [sent2labels(s) for s in eval_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecfceae-3ea8-45b7-ba19-15e03ed51411",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[2])\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860205da-836e-4f04-8763-170df4de032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words, tagsss = set([]), set([])\n",
    "\n",
    "for s in (X_train + X_eval + X_test):\n",
    "    for w in s:\n",
    "        words.add(w.lower())\n",
    "\n",
    "for ts in (y_train + y_eval + y_test):\n",
    "    for t in ts:\n",
    "        tagsss.add(t)\n",
    "\n",
    "word2index = {w: i + 2 for i, w in enumerate(list(words))}\n",
    "word2index['-PAD-'] = 0  # The special value used for padding\n",
    "word2index['-OOV-'] = 1  # The special value used for OOVs\n",
    "\n",
    "tag2index = {t: i + 2 for i, t in enumerate(list(tagsss))}\n",
    "tag2index['-PAD-'] = 0  # The special value used to padding\n",
    "tag2index['-OOV-'] = 1  # The special value used to padding\n",
    "\n",
    "print (len(word2index))\n",
    "print (len(tag2index))\n",
    "print(tag2index)\n",
    "\n",
    "\n",
    "print(tagsss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0691246a-ea07-4e07-a5a5-72f88a397c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences_X, eval_sentences_X, test_sentences_X, train_tags_y, eval_tags_y, test_tags_y = [], [], [], [], [], []\n",
    "\n",
    "for s in X_train:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "\n",
    "    train_sentences_X.append(s_int)\n",
    "\n",
    "for s in X_eval:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "\n",
    "    eval_sentences_X.append(s_int)\n",
    "\n",
    "for s in X_test:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "\n",
    "    test_sentences_X.append(s_int)\n",
    "\n",
    "for s in y_train:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "\n",
    "    train_tags_y.append(s_int)\n",
    "\n",
    "for s in y_eval:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "\n",
    "    eval_tags_y.append(s_int)\n",
    "\n",
    "for s in y_test:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(tag2index[w])\n",
    "        except KeyError:\n",
    "            s_int.append(tag2index['-OOV-'])\n",
    "\n",
    "    test_tags_y.append(s_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab839cb-b45a-4c41-860d-868d4f57180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Longitudes de las Matrices:\")\n",
    "print(len(train_sentences_X))\n",
    "print(len(eval_sentences_X))\n",
    "print(len( test_sentences_X))\n",
    "print(len(train_tags_y))\n",
    "print(len(eval_tags_y))\n",
    "print(len(test_tags_y))\n",
    "\n",
    "print(\"\\nMuestra de Datos presentes en las Matrices con las transformaciones:\\n\")\n",
    "\n",
    "\n",
    "print(train_sentences_X[0])\n",
    "print(eval_sentences_X[0])\n",
    "print(test_sentences_X[0])\n",
    "print(train_tags_y[0])\n",
    "print(eval_tags_y[0])\n",
    "print(test_tags_y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9daf3-60a9-45ca-8df4-533caf452818",
   "metadata": {},
   "source": [
    "Una vez con estas variables, se debe de normalizar las matrices a partir de MAX_LENGTH, requiriendo de un array estático para servir como input de la RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446a9f3-11e1-429f-82c8-7836b807ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_LENGTH=202\n",
    "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "eval_sentences_X = pad_sequences(eval_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
    "train_tags_y = pad_sequences(train_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "eval_tags_y = pad_sequences(eval_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "test_tags_y = pad_sequences(test_tags_y, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "print(train_sentences_X[0])\n",
    "print(train_sentences_X.shape)\n",
    "print(eval_sentences_X[0])\n",
    "print(eval_sentences_X.shape)\n",
    "print(test_sentences_X[0])\n",
    "print(test_sentences_X.shape)\n",
    "print(train_tags_y[0])\n",
    "print(train_tags_y.shape)\n",
    "print(eval_tags_y[0])\n",
    "print(eval_tags_y.shape)\n",
    "print(test_tags_y[0])\n",
    "print(test_tags_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027a94d-6339-4800-a3f9-8e8bc44bcc7d",
   "metadata": {},
   "source": [
    "Y una vez normalizadas las matrices, se procede a representar las listas de indices de etiquetas a una representación one-hot para el procesamiento con el RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977ae89-4d2d-4dd1-aa8f-c3c52aeff181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categoricals(sequences, categories):\n",
    "    cat_sequences = []\n",
    "    for s in sequences:\n",
    "        cats = []\n",
    "        for item in s:\n",
    "            cats.append(np.zeros(categories))\n",
    "            cats[-1][item] = 1.0\n",
    "        cat_sequences.append(cats)\n",
    "    return np.array(cat_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfee0ba-bf72-452b-ae8d-e5fa83b12d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data):\n",
    "    print('Shape of data (BEFORE encode): %s' % str(data.shape))\n",
    "    encoded = to_categorical(data)\n",
    "    print('Shape of data (AFTER  encode): %s\\n' % str(encoded.shape))\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a47fc76-5784-4fc3-98bd-97f5db490c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_tags_y = to_categoricals(train_tags_y, len(tag2index))\n",
    "cat_eval_tags_y  = to_categoricals(eval_tags_y, len(tag2index))\n",
    "cat_test_tags_y  = to_categoricals(test_tags_y, len(tag2index))\n",
    "\n",
    "print(cat_train_tags_y[1])\n",
    "print(len(cat_train_tags_y))\n",
    "print(cat_train_tags_y.shape)\n",
    "print(len(cat_test_tags_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b82c6-d695-4b08-96d0-f807840f3d75",
   "metadata": {},
   "source": [
    "# Parte 2: Entrenamiento del modelo de red"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e118c9ab-42fa-4642-a807-6ae248e7a1a4",
   "metadata": {},
   "source": [
    "Se define la red neuronal para el trabajo de NER usando el modelo LSTM(Bilstm) + CRF + embedding, importando los módulos necesarios para el mismo y también parametrizando la RNN a entrenar.\n",
    "- Se trae el embedding con tamaño de 300.\n",
    "- Se genera el modelo LSTM(Bilstm) + CRF\n",
    "- Se genera una capa de masking para que ignore los valores de 0\n",
    "\n",
    "Una vez hecho esto, se procede a entrenar la red neuronal y a testear los resultados de la misma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1fe828-7779-4b97-b7b7-d59e2f0fef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: No se ha hecho nada diferente por el momento\n",
    "\n",
    "from tf2crf import CRF as crf6\n",
    "from wrapper import ModelWithCRFLoss, ModelWithCRFLossDSCLoss\n",
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "from tensorflow.keras.layers import Concatenate, Lambda, Input, LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, InputLayer, Activation, Flatten, Masking\n",
    "from tensorflow.keras.optimizers import Adam, schedules\n",
    "input = Input(shape=(MAX_LENGTH,))\n",
    "word_embedding_size = 300\n",
    "EMBED_DIM=300\n",
    "# Embedding Layer\n",
    "model = Embedding(input_dim=len(word2index),\n",
    "                output_dim=word_embedding_size,\n",
    "                input_length=MAX_LENGTH,\n",
    "                mask_zero=False)(input)\n",
    "\n",
    "# BI-LSTM Layer\n",
    "model = Bidirectional(LSTM(units=50,\n",
    "                     return_sequences=True,\n",
    "                     dropout=0.5,\n",
    "                     recurrent_dropout=0.5))(model)\n",
    "model  = Dropout(0.5, name='dropout_lstm')(model)\n",
    "model  = Dense(units=EMBED_DIM * 2, activation='relu')(model)\n",
    "model  = Dense(units=len(tag2index), activation='relu')(model)\n",
    "\n",
    "model  = Masking(mask_value=0.,input_shape=(MAX_LENGTH, len(tag2index)))(model)\n",
    "\n",
    "\n",
    "crf = crf6(units=len(tag2index), name=\"ner_crf\")\n",
    "predictions = crf(model)\n",
    "\n",
    "base_model = Model(inputs=input, outputs=predictions)\n",
    "model = ModelWithCRFLoss(base_model, sparse_target=True)\n",
    "\n",
    "model.compile(optimizer='adam')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883e776-e7a2-4e28-8055-92f719505a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(train_sentences_X, cat_train_tags_y,\n",
    "                       validation_data=(eval_sentences_X, cat_eval_tags_y),\n",
    "                       batch_size=128,\n",
    "                       epochs=50,\n",
    "                       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d90aa-4c7b-4884-b138-9a052d59ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tag2index)\n",
    "print(test_sentences_X)\n",
    "y_pred= model.predict(test_sentences_X)\n",
    "print(y_pred.shape)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb09e4c-fe54-4fd0-9481-226625cfe92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import build_matrix_embeddings as bme, plot_model_performance, logits_to_tokens, report_to_df\n",
    "index2tag = {i: t for t, i in tag2index.items()}\n",
    "print(index2tag)\n",
    "y1_pred = logits_to_tokens(y_pred, index2tag)\n",
    "print(y1_pred[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d9d47-b7b8-478a-b7f6-efd5be17f762",
   "metadata": {},
   "source": [
    "## Calidad obtenida del modelo\n",
    "\n",
    "Se evalua la calidad de los resultados del modelo usando las siguientes métricas: *precision, recall, accuracy* y *F1-score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc937ab9-d0d4-4c83-a503-05f7432c4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report as seqclarep\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "print(\"precision: {:.1%}\".format(precision_score(y1_true, y1_pred)))\n",
    "print(\"   recall: {:.1%}\".format(recall_score(y1_true,    y1_pred)))\n",
    "print(\" accuracy: {:.1%}\".format(accuracy_score(y1_true,  y1_pred)))\n",
    "print(\" F1-score: {:.1%}\".format(f1_score(y1_true,        y1_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b947ac45-185b-4407-8883-966e1210f065",
   "metadata": {},
   "source": [
    "Se genera un reporte de la clasificación basada en las etiquetas predichas y las reales, esto brindado en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3aa1f6-3de6-4026-bdb9-5d95f46f4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "li1 = sum(y1_true, [])\n",
    "li2 = sum(y1_pred, [])\n",
    "\n",
    "results = pd.DataFrame(columns=['Expected', 'Predicted'])\n",
    "\n",
    "results['Expected'] = li1\n",
    "results['Predicted'] = li2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fccdb6-6160-4d08-9fb4-443632379b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report as eskclarep\n",
    "report = eskclarep(results['Expected'], results['Predicted'])\n",
    "\n",
    "print(report_to_df(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3433b-4e95-4920-9a55-940d1f2f1a1c",
   "metadata": {},
   "source": [
    "Por último, se realizan evaluaciones del modelo a partir de algunas oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c99ce-8ea1-4818-8fa1-92b4b7c75ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample1 = [\n",
    "    \"James Rodriguez es el jugador colombiano más importante con Radamel Falcao.\".split(),\n",
    "    \" Jugadores de la selección Colombia que juegan en el Reino Unido\".split()\n",
    "]\n",
    "\n",
    "print(test_sample1)\n",
    "\n",
    "test_sample2 = [\n",
    "    \"La federación Nacional de cafeteros de Colombia es dirigida por Horacio Sánchez\".split(),\n",
    "    \" y se ubica en las ciudades de  Cali y Medellín con el instituto colombiano del café \".split()\n",
    "]\n",
    "\n",
    "print(test_sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53bc58-c8c5-4962-bf78-06bff6ea5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples_X = []\n",
    "for s in test_sample2:\n",
    "    s_int = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            s_int.append(word2index[w.lower()])\n",
    "        except KeyError:\n",
    "            s_int.append(word2index['-OOV-'])\n",
    "    test_samples_X.append(s_int)\n",
    "\n",
    "test_samples_X = pad_sequences(test_samples_X, maxlen=MAX_LENGTH, padding='post')\n",
    "print(test_samples_X)\n",
    "print(test_samples_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b1961-c8a2-45c3-8604-f667f0225d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_samples_X)\n",
    "print(predictions, predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ea8d2-3522-4029-a5b5-727e4fb09338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(predictions))\n",
    "log_tokens = logits_to_tokens(predictions, {i: t for t, i in tag2index.items()})\n",
    "print(log_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b160eb-4901-4278-a3ec-32fac5bf6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate\n",
    "from tabulate import tabulate\n",
    "\n",
    "heads1 = test_sample2[0]\n",
    "body1 = [log_tokens[0][:len(test_sample2[0])]]\n",
    "\n",
    "heads2 = test_sample2[1]\n",
    "body2 = [log_tokens[1][:len(test_sample2[1])]]\n",
    "\n",
    "print(tabulate(body1, headers=heads1))\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "print(tabulate(body2, headers=heads2))\n",
    "\n",
    "## postagging Freeling 4.1\n",
    "\n",
    "## El      hombre   bajo     corre    bajo  el      puente   con  bajo  índice   de  adrenalina  .\n",
    "## DA0MS0  NCMS000  AQ0MS00  VMIP3S0  SP    DA0MS0  NCMS000  SP   SP    NCMS000  SP  NCFS000     Fp\n",
    "\n",
    "\n",
    "## pos tagger Stanford NLP\n",
    "\n",
    "## El      hombre   bajo     corre    bajo  el      puente   con    bajo   índice  de    adrenalina  .\n",
    "## da0000  nc0s000  aq0000   vmip000  sp000 da0000  nc0s000  sp000  aq0000 nc0s000 sp000 nc0s000     fp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
